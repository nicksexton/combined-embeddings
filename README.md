# combined-embeddings
Code that creates a new set of embeddings through Concatenating multiple other sources (e.g., from GloVe and skip-gram sources. Optional step of then running PCA to reduce dimensions of embeddings.



See:

[Ghannay, S., Favre, B., Esteve, Y., & Camelin, N. (n.d.). Word Embeddings Evaluation and Combination](https://pdfs.semanticscholar.org/343d/39534682bb7b2eec14f573360877eb80cd59.pdf)

[Ghannay, S., Estève, 
Y., Camelin, N., Dutrey, C., Santiago, F., & Adda-Decker, M. (2015). Combining continuous word representation and prosodic features for asr error prediction](https://scholar.google.co.uk/scholar?hl=en&as_sdt=0%2C5&q=Combining+continous+word+representation+and+prosodic+features+for+asr+error+prediction.&btnG=) In International Conference on Statistical Language and Speech Processing (pp. 84–95). 
